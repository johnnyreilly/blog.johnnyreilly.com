"use strict";(self.webpackChunkjohnnyreilly_com=self.webpackChunkjohnnyreilly_com||[]).push([["29090"],{33265:function(e,n,t){t.r(n),t.d(n,{assets:function(){return l},contentTitle:function(){return s},default:function(){return m},frontMatter:function(){return a},metadata:function(){return r},toc:function(){return u}});var r=t(81183),i=t(85893),o=t(50065);let a={slug:"using-kernel-memory-to-chunk-documents-into-azure-ai-search",title:"Using Kernel Memory to Chunk Documents into Azure AI Search",authors:"johnnyreilly",image:"./title-image.png",tags:["azure","c#","asp.net","ai"],description:"To build RAG (Retrieval Augmented Generation) experiences, where LLMs can query documents, you need a strategy to chunk those documents. Kernel Memory supports this.",hide_table_of_contents:!1},s=void 0,l={image:t(36167).Z,authorsImageUrls:[void 0]},u=[];function c(e){let n={a:"a",img:"img",p:"p",...(0,o.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(n.p,{children:["I've recently been working on building retrieval augmented generation (RAG) experiences into applications; building systems where large language models (LLMs) can query documents. To achieve this, we first need a strategy to chunk those documents and make them LLM-friendly. ",(0,i.jsx)(n.a,{href:"https://github.com/microsoft/kernel-memory",children:"Kernel Memory"}),", a sister project of ",(0,i.jsx)(n.a,{href:"https://github.com/microsoft/semantic-kernel",children:"Semantic Kernel"})," supports this."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"title image reading &quot;Using Kernel Memory to Chunk Documents into Azure AI Search&quot; with the Azure Open AI / Azure AI Search logos",src:t(83459).Z+"",width:"800",height:"450",loading:"eager",fetchpriority:"high"})})]})}function m(e={}){let{wrapper:n}={...(0,o.a)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},36167:function(e,n,t){t.d(n,{Z:function(){return r}});let r=t.p+"assets/images/title-image-337c58e5e55f92f59a1d1db49366ec04.png"},83459:function(e,n,t){t.d(n,{Z:function(){return r}});let r=t.p+"assets/images/title-image-337c58e5e55f92f59a1d1db49366ec04.png"},50065:function(e,n,t){t.d(n,{Z:function(){return s},a:function(){return a}});var r=t(67294);let i={},o=r.createContext(i);function a(e){let n=r.useContext(o);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),r.createElement(o.Provider,{value:n},e.children)}},81183:function(e){e.exports=JSON.parse('{"permalink":"/using-kernel-memory-to-chunk-documents-into-azure-ai-search","editUrl":"https://github.com/johnnyreilly/blog.johnnyreilly.com/edit/main/blog-website/blog/2024-04-21-using-kernel-memory-to-chunk-documents-into-azure-ai-search/index.md","source":"@site/blog/2024-04-21-using-kernel-memory-to-chunk-documents-into-azure-ai-search/index.md","title":"Using Kernel Memory to Chunk Documents into Azure AI Search","description":"To build RAG (Retrieval Augmented Generation) experiences, where LLMs can query documents, you need a strategy to chunk those documents. Kernel Memory supports this.","date":"2024-04-21T00:00:00.000Z","tags":[{"inline":false,"label":"Azure","permalink":"/tags/azure","description":"The Microsoft cloud platform."},{"inline":false,"label":"C#","permalink":"/tags/csharp","description":"The C# programming language."},{"inline":false,"label":"ASP.NET","permalink":"/tags/asp-net","description":"The web framework built by Microsoft."},{"inline":false,"label":"AI","permalink":"/tags/ai","description":"All things AI - Artificial Intelligence, Large Language Models and the like."}],"readingTime":16.155,"hasTruncateMarker":true,"authors":[{"name":"John Reilly","title":"OSS Engineer - TypeScript, Azure, React, Node.js, .NET","url":"https://johnnyreilly.com/about","imageURL":"https://johnnyreilly.com/img/profile.jpg","key":"johnnyreilly","page":null}],"frontMatter":{"slug":"using-kernel-memory-to-chunk-documents-into-azure-ai-search","title":"Using Kernel Memory to Chunk Documents into Azure AI Search","authors":"johnnyreilly","image":"./title-image.png","tags":["azure","c#","asp.net","ai"],"description":"To build RAG (Retrieval Augmented Generation) experiences, where LLMs can query documents, you need a strategy to chunk those documents. Kernel Memory supports this.","hide_table_of_contents":false},"unlisted":false,"prevItem":{"title":"Large Language Models, Open API, View Models and the Backend for Frontend Pattern","permalink":"/large-language-models-view-models-backend-for-frontend"},"nextItem":{"title":"Overview of webpack, a JavaScript bundler","permalink":"/webpack-overview"}}')}}]);